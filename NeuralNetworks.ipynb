{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d12752-992d-413c-b10f-e2cd725a3f55",
   "metadata": {},
   "source": [
    "# Feed forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b85c7a-2956-48fc-be7c-12387115f81b",
   "metadata": {},
   "source": [
    "### Out = step( x1.w1 + x2.w2 + x3.w3 ... + c.w0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d399fe5c-6278-4746-a97f-f49da4442667",
   "metadata": {},
   "source": [
    "## Activation function = whether the output be given or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30654ac-00ba-4f7e-9a19-72c5a73c6041",
   "metadata": {},
   "source": [
    "to handle non linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7750e90-cced-4514-a0eb-1cbe0f7f9952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71391641]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "inputs = np.array( [0.5, 0.3, 0.2] )\n",
    "weights = np.random.rand(len(inputs))\n",
    "\n",
    "bias = np.random.rand(1)\n",
    "\n",
    "total_input = np.dot(inputs, weights) + bias\n",
    "\n",
    "output = sigmoid(total_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0da147-7001-4397-8da5-43791a35f8f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416a040-a778-43fe-bc6e-c20224162d93",
   "metadata": {},
   "source": [
    "## Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972ccbe-db22-4462-984f-b83bd6dbc7e8",
   "metadata": {},
   "source": [
    "dataset has rows = 10k\n",
    "batch size = 100\n",
    "\n",
    "so, iterations(steps) = 100\n",
    "After 100 iterations 1 epoch is done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b49b1-1ed8-446f-bf86-0308ebb62ffc",
   "metadata": {},
   "source": [
    "All neurons in the same layer has the same activation fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2fbac0-5466-4a04-bbc5-df69d7d79f0f",
   "metadata": {},
   "source": [
    "## ReLU Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c3ba7-391a-42a7-9297-8d732ccae4ba",
   "metadata": {},
   "source": [
    "f(x) = max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc30ae0-d88a-4bba-9a6f-b8a06099e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return(max(0,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7badee-a098-4db8-81f0-80682b0b62b9",
   "metadata": {},
   "source": [
    "## Softmax Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a1667-1039-400b-9449-edd700540875",
   "metadata": {},
   "source": [
    "f(xi) = e^xi / sigma(j e^xj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bebfa008-596e-40c5-96a7-76ddadb5fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    expx = np.exp(x - np.max(x))\n",
    "    return expx / expx.sum(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481935a7-0a11-4538-8d68-6a374f636bd5",
   "metadata": {},
   "source": [
    "for binary: use sigmoid,\n",
    "for multi: use softmax,\n",
    "for unsure: use relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e468b-901b-4c7a-ab65-eb6384394fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
